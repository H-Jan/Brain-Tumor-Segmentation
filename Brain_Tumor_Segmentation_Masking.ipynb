{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "###Libraries and imports\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "import gzip\n",
        "import glob\n",
        "import gc\n",
        "import cv2 as cv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "import PIL\n",
        "import scipy.misc\n",
        "import skimage\n",
        "import nibabel as nib\n",
        "import pdb\n",
        "from matplotlib.patches import Rectangle\n",
        "import pickle\n",
        "from skimage.metrics import hausdorff_distance\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from tensorflow import keras\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
        "from skimage.measure import label,regionprops, perimeter\n",
        "from skimage.morphology import binary_dilation, binary_opening\n",
        "from skimage.filters import roberts, sobel\n",
        "from skimage import measure, feature\n",
        "from skimage.segmentation import clear_border\n",
        "from skimage import data\n",
        "from skimage.io import imread\n",
        "from scipy import ndimage as ndi\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Activation,\n",
        "    Conv3D,\n",
        "    Conv3DTranspose,\n",
        "    MaxPooling3D,\n",
        "    UpSampling3D,\n",
        ")\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import models, layers, regularizers\n",
        "from skimage.morphology import binary_closing"
      ],
      "metadata": {
        "id": "dVtLG8Bl5ReQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNrGIr-ngCOW",
        "outputId": "b2b40bb4-9c8d-4488-f050-6799492bc631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to BraTS2021 folder\n",
        "data_dir = '/content/drive/My Drive/BraTS2021'\n",
        "\n",
        "# List all files in the directory\n",
        "files = os.listdir(data_dir)\n",
        "print(\"Files in BraTS2021:\", files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwl2KTJXuiT-",
        "outputId": "24829ec5-6203-40e8-c2fd-57805f9dad54"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in BraTS2021: ['BraTS2021_00495_t1ce.nii.gz', 'BraTS2021_00495_t2.nii.gz', 'BraTS2021_00495_flair.nii.gz', 'BraTS2021_00495_t1.nii.gz', 'BraTS2021_00495_seg.nii.gz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "\n",
        "# File paths\n",
        "t2_path = os.path.join(data_dir, 'BraTS2021_00495_t2.nii.gz')\n",
        "t1ce_path = os.path.join(data_dir, 'BraTS2021_00495_t1ce.nii.gz')\n",
        "t1_path = os.path.join(data_dir, 'BraTS2021_00495_t1.nii.gz')\n",
        "flair_path = os.path.join(data_dir, 'BraTS2021_00495_flair.nii.gz')\n",
        "seg_path = os.path.join(data_dir, 'BraTS2021_00495_seg.nii.gz')\n",
        "\n",
        "# Load images\n",
        "t2_img = nib.load(t2_path).get_fdata()\n",
        "t1ce_img = nib.load(t1ce_path).get_fdata()\n",
        "t1_img = nib.load(t1_path).get_fdata()\n",
        "flair_img = nib.load(flair_path).get_fdata()\n",
        "seg_img = nib.load(seg_path).get_fdata()\n",
        "\n",
        "print(\"Data Loaded Successfully\")\n",
        "print(\"T2 shape:\", t2_img.shape)\n",
        "print(\"T1ce shape:\", t1ce_img.shape)\n",
        "print(\"T1 shape:\", t1_img.shape)\n",
        "print(\"FLAIR shape:\", flair_img.shape)\n",
        "print(\"Segmentation mask shape:\", seg_img.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSz34TyYumww",
        "outputId": "282ae279-079c-4292-d655-58ac9f6579b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded Successfully\n",
            "T2 shape: (240, 240, 155)\n",
            "T1ce shape: (240, 240, 155)\n",
            "T1 shape: (240, 240, 155)\n",
            "FLAIR shape: (240, 240, 155)\n",
            "Segmentation mask shape: (240, 240, 155)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize images\n",
        "def normalize(image):\n",
        "    return (image - np.mean(image)) / np.std(image)"
      ],
      "metadata": {
        "id": "Djyq0PsmyqYD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2_img = normalize(t2_img)\n",
        "t1ce_img = normalize(t1ce_img)\n",
        "t1_img = normalize(t1_img)\n",
        "flair_img = normalize(flair_img)"
      ],
      "metadata": {
        "id": "n64WhrZ65hVH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack modalities along the channel axis\n",
        "multi_modal_img = np.stack([t2_img, t1ce_img, t1_img, flair_img], axis=0)  # Shape: (4, 240, 240, 155)\n",
        "# Convert segmentation mask to integers\n",
        "seg_img = seg_img.astype(np.int64)  # Ensure compatibility with PyTorch\n",
        "\n",
        "print(\"Multi-modal image shape:\", multi_modal_img.shape)\n",
        "print(\"Segmentation mask shape:\", seg_img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPUquy3I5jnp",
        "outputId": "6bcbe6b4-ed99-4c02-b82c-35b09482926e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-modal image shape: (4, 240, 240, 155)\n",
            "Segmentation mask shape: (240, 240, 155)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class BrainDataset(Dataset):\n",
        "    def __init__(self, images, masks):\n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[-1]  # Number of slices\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return a single slice\n",
        "        image = self.images[:, :, :, idx]  # Shape: (4, 240, 240)\n",
        "        mask = self.masks[:, :, idx]      # Shape: (240, 240)\n",
        "        return torch.tensor(image, dtype=torch.float32), torch.tensor(mask, dtype=torch.long)\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = BrainDataset(multi_modal_img, seg_img)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "print(\"Dataset and DataLoader Prepared\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-iE_Qdt5pvq",
        "outputId": "40b8e31e-e459-4f1a-a21b-09e7fb7a36ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset and DataLoader Prepared\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the DataLoader to fetch batches\n",
        "for batch_idx, (images, masks) in enumerate(dataloader):\n",
        "    print(f\"Batch {batch_idx}:\")\n",
        "    print(\"Image batch shape:\", images.shape)  # Expected: (Batch_Size, 4, 240, 240)\n",
        "    print(\"Mask batch shape:\", masks.shape)    # Expected: (Batch_Size, 240, 240)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxEVBJHq5yLY",
        "outputId": "c34388fd-d730-4f62-e065-c765daf69fbc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0:\n",
            "Image batch shape: torch.Size([1, 4, 240, 240])\n",
            "Mask batch shape: torch.Size([1, 240, 240])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ajMifd_F7dci"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}